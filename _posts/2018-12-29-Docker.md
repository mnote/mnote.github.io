---
layout: default
title: Docker
---

### Docker Concepts

[Get Started](https://docs.docker.com/get-started/)

Docker is a platform for developers and sysadmins to _develop_, _deploy_, and _run_ applications with containers. _The use of Linux containers to deploy applications is called containerization_. 

Docker is an open platform for developing, shipping, and running applications. Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. With Docker, you can manage your infrastructure in the same ways you manage your applications. By taking advantage of Docker’s methodologies for shipping, testing, and deploying code quickly, you can significantly reduce the delay between writing code and running it in production.

Define a container with `Dockerfile`

A single container running in a service is called a `task`. Tasks are given unique IDs that numerically increment, up to the number of replicas you defined in docker-compose.yml.

#### Swarm
A swarm is a cluster of machines running Docker

Multi-container, multi-machine applications are made possible by joining multiple machines into a “Dockerized” cluster called a `swarm`.

A swarm is a group of machines that are running Docker and joined into a cluster. After that has happened, you continue to run the Docker commands you’re used to, but now they are executed on a cluster by a swarm manager. The machines in a swarm can be physical or virtual. After joining a swarm, they are referred to as nodes.

Swarm managers can use several strategies to run containers, such as “emptiest node” -- which fills the least utilized machines with containers. Or “global”, which ensures that each machine gets exactly one instance of the specified container. You instruct the swarm manager to use these strategies in the Compose file, just like the one you have already been using.

Swarm managers are the only machines in a swarm that can execute your commands, or authorize other machines to join the swarm as workers. Workers are just there to provide capacity and do not have the authority to tell any other machine what it can and cannot do.

Up until now, you have been using Docker in a single-host mode on your local machine. But Docker also can be switched into swarm mode, and that’s what enables the use of swarms. Enabling swarm mode instantly makes the current machine a swarm manager. From then on, Docker runs the commands you execute on the swarm you’re managing, rather than just on the current machine.

#### Stack

A stack is a group of interrelated services that share dependencies, and can be orchestrated and scaled together.

Docker For Mac > Preferences > File Sharing: /Users

`sudo mkdir ~/docker/data`

```
    volumes:
      - "~/docker/data:/data"
```

`docker swarm init`

`docker stack deploy -c docker-compose-redis.yml hello`

`docker service ls`

`docker service ps hello_web`

`docker container ls`

`curl -4 http://localhost:4000`

`docker stack rm hello`

`docker swarm leave --force`


### Docker Download

[DockerWithoutLogin](https://github.com/AlexTalavari/DockerWithoutLogin)  
[Download Docker CE without logging in](https://github.com/docker/docker.github.io/issues/6910)


### Docker Mirror

[DaoCloud Mirror](https://www.daocloud.io/mirror)

Docker For Mac > Preferences > Daemon > Registry mirrors:
`https://www.daocloud.io/mirror`


```

$ ls .docker/
config.json  daemon.json

$ cat .docker/daemon.json
{
  "debug" : true,
  "registry-mirrors" : [
    "http://f1361db2.m.daocloud.io"
  ],
  "experimental" : false
}

$ cat .docker/config.json
{
  "credSstore" : "osxkeychain",
  "credsStore" : "osxkeychain",
  "auths" : {
    "https://index.docker.io/v1/" : {

    }
  },
  "stackOrchestrator" : "swarm",
  "HttpHeaders" : {
    "User-Agent" : "Docker-Client/18.09.0 (darwin)"
  }
}

```

save `daemon.json` and restart the docker service:

```
sudo service docker restart
```

>Error response from daemon: Get https://registry-1.docker.io/v2/
>
>Error response from daemon: Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection (Client.Timeout exceeded while awaiting headers)

1. set System Preferences > Network > Wi-Fi > Advanced > DNS to 8.8.8.8
2. create an account @ hub.docker.com  and log in docker in console:
3. Docker Tray Icon > Sign Out > Sign In
4. `docker login`
5. `docker run hello-world`
6. `docker images`


#### port mapping
mapping your machine’s port 4000 to the container’s published port 80 using -p:
`docker run -p 4000:80 hello`

This port remapping of 4000:80 demonstrates the difference between EXPOSE within the Dockerfile and what the publish value is set to when running docker run -p. In later steps, map port 4000 on the host to port 80 in the container

To find the IP address, use the command `docker-machine ip`

```bash
docker build -t hello .  # Create image using this directory's Dockerfile
docker run -p 4000:80 hello  # Run "name" mapping port 4000 to 80
docker run -d -p 4000:80 hello         # Same thing, but in detached mode
docker container ls                                # List all running containers
docker container ls -a             # List all containers, even those not running
docker container stop <hash>           # Gracefully stop the specified container
docker container kill <hash>         # Force shutdown of the specified container
docker container rm <hash>        # Remove specified container from this machine
docker container rm $(docker container ls -a -q)         # Remove all containers
docker image ls -a                             # List all images on this machine
docker image rm <image id>            # Remove specified image from this machine
docker image rm $(docker image ls -a -q)   # Remove all images from this machine
docker login             # Log in this CLI session using your Docker credentials
docker tag <image> username/repository:tag  # Tag <image> for upload to registry
docker push username/repository:tag            # Upload tagged image to registry
docker run username/repository:tag                   # Run image from a registry
```

### Docker Container


`docker ps -a`  
`docker container ls`

How to See full command of running/stopped container in Docker: 
`docker inspect -f "{{.Name}} {{.Config.Cmd}}" $(docker ps -a -q)`

`docker ps -a --no-trunc` will display the full command along with the other details of the running containers.

`docker inspect -f "{{.Path}} {{.Args}} ({{.Id}})" $(docker ps -a -q)`

`docker stop $(docker ps -a -q)`

`docker rm $(docker ps -a -q)`

`docker rm $(docker images -q)`
`docker rmi $(docker images -q)`

`docker ps --filter 'status=Exited' -a | xargs docker stop docker images --filter "dangling=true" -q | xargs docker rmi`

[Stop and Remove Containers](https://coderwall.com/p/ewk0mq/stop-remove-all-docker-containers)


Docker does not have a command to update images that you have already pulled. The only way is to pull all images again using docker pull <image> command. This simple one-liner can help you update all images at once.

`docker images |grep -v REPOSITORY|awk '{print $1}'|xargs -L1 docker pull`

[Update All Docker Images](http://www.googlinux.com/update-all-docker-images/index.html)

recursive_remove_image

```bash
recursive_remove_image() {
  for image in $(docker images --quiet --filter "since=${1}")
  do
    if [ $(docker history --quiet ${image} | grep ${1}) ]
    then
      recursive_remove_image "${image}"
    fi
  done
  echo "Removing: ${1}"
  docker rmi -f ${1}
}

```

`recursive_remove_image <image-id>`


### docker-compose.yml

A docker-compose.yml file is a YAML file that defines how Docker containers should behave in production.

```bash
docker swarm init
docker stack ls                                            # List stacks or apps
docker stack deploy -c <composefile> <appname>  # Run the specified Compose file
docker service ls                 # List running services associated with an app
docker service ps <service>                  # List tasks associated with an app
docker inspect <task or container>                   # Inspect task or container
docker container ls -q                                      # List container IDs
docker stack rm <appname>                             # Tear down an application
docker swarm leave --force      # Take down a single node swarm from the manager
```

### Docker and TiDB

[TiSpark](https://github.com/pingcap/tispark)

```bash

cd ~/pingcap

git clone https://github.com/pingcap/tispark.git
#mvn clean install -Dmaven.test.skip=true -Pspark-2.3.2

cd tispark

docker-compose -f docker-compose.yaml up -d
docker container ls
docker-compose stop

hosts:
127.0.0.1 pd0
127.0.0.1 tikv0


wget http://download.pingcap.org/tispark-sample-data.tar.gz
tar zxvf tispark-sample-data.tar.gz

cd tispark-sample-data
mysql --default-character-set=utf8 --local-infile=1 -u root -h 127.0.0.1 -P 4000 < ./dss.ddl


wget http://download.pingcap.org/tispark-latest-linux-amd64.tar.gz
tar zxvf tispark-latest-linux-amd64.tar.gz
cp core/target/tispark-core-2.0-SNAPSHOT-jar-with-dependencies.jar ~/spark/jars/

#use spark 2.3.2
cd ~/spark
./sbin/start-master.sh
./sbin/start-slave.sh spark://spark-master-hostname:7077


vim ~/spark/conf/spark-defaults.conf
spark.sql.extensions 			   org.apache.spark.sql.TiExtensions
spark.tispark.pd.addresses		   127.0.0.1:2379

cd ~/spark
./bin/spark-shell --master spark://spark-master-hostname:7077 --total-executor-cores 2

spark.sql("use tpch_001")

spark.sql("select count(*) from lineitem").show

spark.sql("select ti_version()").show()

```


[Run TiDB with Docker (Standalone mode)](https://github.com/pingcap/tidb/blob/master/docs/QUICKSTART.md)

```
docker pull pingcap/tidb:latest
docker run --name tidb-server -d -p 4000:4000 pingcap/tidb:latest
```

`mysql -h 127.0.0.1 -P 4000 -u root -D test --prompt="tidb> "  `


--

[How To Spin Up an HTAP Database in 5 Minutes with TiDB + TiSpark](https://www.pingcap.com/blog/how_to_spin_up_an_htap_database_in_5_minutes_with_tidb_tispark/)


`docker-compose up -d`

`docker-compose stop`


>ERROR 1105 (HY000): Unknown charset id 255

This error is because of the charset of the operating system. Use `echo $LANG` or `env` to see the charset. If it is `utf8`, you can connect to TiDB using `mysql --default-character-set=utf8`

That is: `mysql --default-character-set=utf8 -h 127.0.0.1 -P 4000  -u root`

>ERROR 2 (HY000) at line 76: File 'customer.tbl' not found (OS errno 2 - No such file or directory)

`cd tispark-sample-data`
`mysql --default-character-set=utf8 --local-infile=1 -u root -h 127.0.0.1 -P 4000 < ./dss.ddl`

*dss.dll* add `DROP DATABASE IF EXISTS TPCH_001;`

>OCI runtime exec failed: exec failed: container_linux.go:348: starting container process caused "exec: \"/opt/spark-2.1.1-bin-hadoop2.7/bin/spark-shell\": stat /opt/spark-2.1.1-bin-hadoop2.7/bin/spark-shell: no such file or directory": unknown

Find spark dir using:  
`docker ps -a`  

Launch TiSpark:
`docker-compose exec tispark-master  /opt/spark/bin/spark-shell`

